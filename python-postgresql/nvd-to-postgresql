#!/usr/bin/env python3
# PYTHON_ARGCOMPLETE_OK

import argparse
from time import strftime
import requests
import pandas as panda
import pyodbc
import json
import gzip
import inspect
import sys
import os
import fnmatch
import mmap
import re
import subprocess
try: 
    import argcomplete
except ImportError: 
    argcomplete = None
import shutil
import datetime

parser = argparse.ArgumentParser(description="Program for automating NVD downloads and parsing")
task_types_subparsers = parser.add_subparsers(help="Task Types or Sub-Command (type sub-command -h or --help for more info)", dest="task_type")
download_parser = task_types_subparsers.add_parser("download", help="Task for downloading NVD JSON Data Feeds")
download_options_group = download_parser.add_argument_group('Download Optional Modifiers')
#download_subparsers = download_parser.add_subparsers(help="Download Actions", dest="download_action")
download_options_group.add_argument("--incremental", dest="incremental", default=False, action="store_true", help="Only download the recent and modified NVD JSON Data Feeds")
import_parser = task_types_subparsers.add_parser("import", help="Task for importing NVD JSON Data Feeds")
import_options_group = import_parser.add_argument_group('Import Optional Modifiers')
#import_subparsers = import_parser.add_subparsers(help="Import Actions", dest="import_action")
import_options_group.add_argument("--use-defaults", dest="defaults", default=False, action="store_true", help="Use default values for import")
import_options_group.add_argument("--incremental", dest="incremental", default=False, action="store_true", help="Only import the recent and modified NVD JSON Data Feeds")

if argcomplete is not None:
    argcomplete.autocomplete(parser)

args = parser.parse_args()

def download_feeds():
    print("Hello world download!")
    years = list(range(2002, datetime.date.today().year+1))
    base_url = "https://nvd.nist.gov/feeds/json/cve/1.1/"
    base_download_path = "./downloads/"
    os.makedirs(os.path.dirname(base_download_path), exist_ok=True)
    if not incremental:
        for year in years:
            file_name = "nvdcve-1.1-" + str(year) + ".json.gz"
            file = requests.get(base_url + file_name)
            
            with open(base_download_path + file_name, "wb") as f:
                f.write(file.content)

    file_name = "nvdcve-1.1-recent.json.gz"
    file = requests.get(base_url + file_name)
    with open(base_download_path + file_name, "wb") as f:
        f.write(file.content)

    file_name = "nvdcve-1.1-modified.json.gz"
    file = requests.get(base_url + file_name)
    with open(base_download_path + file_name, "wb") as f:
        f.write(file.content)

def import_feeds():
    print("Hello world import!")
    years = list(range(2002, datetime.date.today().year+1))
    base_download_path = "./downloads/"
    conn_str = (
        "DRIVER={PostgreSQL ANSI};"
        "DATABASE=mgt516;"
        "UID=mgt516;"
        "PWD=<pass>;"
        "SERVER=172.27.46.71;"
        "PORT=5432;"
        )
    conn = pyodbc.connect(conn_str)
    conn.setdecoding(pyodbc.SQL_WCHAR, encoding='utf-8')
    conn.setencoding(encoding='utf-8')
    cursor = conn.cursor()
    df_concat = panda.DataFrame()
    if not incremental:
        for year in years:
            file_name = "nvdcve-1.1-" + str(year) + ".json.gz"
            with gzip.open(base_download_path + file_name, 'r') as uf:
                json_bytes = uf.read()
            json_str = json_bytes.decode("utf-8")
            json_dict = json.loads(json_str)
            df = panda.json_normalize(json_dict, record_path="CVE_Items", meta=["CVE_data_type", "CVE_data_format"], max_level=1)
            df["object_filename"] = file_name
            df["object_download_datetime"] = datetime.date.today().strftime("%Y:%m:%d")    
            df_impact = panda.json_normalize(json_dict, record_path="CVE_Items", meta=["CVE_data_type", "CVE_data_format"], max_level=3)
            impact_fields = ["impact.baseMetricV2.cvssV2.version","impact.baseMetricV2.cvssV2.vectorString","impact.baseMetricV2.cvssV2.accessVector","impact.baseMetricV2.cvssV2.accessComplexity","impact.baseMetricV2.cvssV2.authentication","impact.baseMetricV2.cvssV2.confidentialityImpact","impact.baseMetricV2.cvssV2.integrityImpact","impact.baseMetricV2.cvssV2.availablityImpact","impact.baseMetricV2.cvssV2.baseScore","impact.baseMetricV2.severity","impact.baseMetricV2.exploitabilityScore","impact.baseMetricV2.impactScore","impact.baseMetricV2.acInsufInfo","impact.baseMetricV2.obtainAllPrivilege","impact.baseMetricV2.obtainUserPrivilege","impact.baseMetricV2.obtainOtherPrivilege","impact.baseMetricV2.userInteractionRequired","impact.baseMetricV3.cvssV3.version","impact.baseMetricV3.cvssV3.vectorString","impact.baseMetricV3.cvssV3.attackVector","impact.baseMetricV3.cvssV3.attackComplexity","impact.baseMetricV3.cvssV3.privilegesRequired","impact.baseMetricV3.cvssV3.userInteraction","impact.baseMetricV3.cvssV3.scope","impact.baseMetricV3.cvssV3.confidentialityImpact","impact.baseMetricV3.cvssV3.integrityImpact","impact.baseMetricV3.cvssV3.availabilityImpact","impact.baseMetricV3.cvssV3.baseScore","impact.baseMetricV3.cvssV3.baseSeverity","impact.baseMetricV3.exploitabilityScore","impact.baseMetricV3.impactScore"]
            for column in impact_fields:
                if column not in df_impact.columns:
                    df_impact[column] = ""

            df_concat = panda.concat([
                df_concat, 
                panda.concat([df,df_impact[impact_fields]], axis=1)
            ])

    file_name = "nvdcve-1.1-recent.json.gz"
    with gzip.open(base_download_path + file_name, 'r') as uf:
        json_bytes = uf.read()
    json_str = json_bytes.decode("utf-8")
    json_dict = json.loads(json_str)
    df = panda.json_normalize(json_dict, record_path="CVE_Items", meta=["CVE_data_type", "CVE_data_format"], max_level=1)
    df["object_filename"] = file_name
    df["object_download_datetime"] = datetime.date.today().strftime("%Y:%m:%d")    
    df_impact = panda.json_normalize(json_dict, record_path="CVE_Items", meta=["CVE_data_type", "CVE_data_format"], max_level=3)
    with open(base_download_path + file_name + "-test.csv", "w") as f:
        f.write(df_impact.head(100).to_csv())    
    impact_fields = ["impact.baseMetricV2.cvssV2.version","impact.baseMetricV2.cvssV2.vectorString","impact.baseMetricV2.cvssV2.accessVector","impact.baseMetricV2.cvssV2.accessComplexity","impact.baseMetricV2.cvssV2.authentication","impact.baseMetricV2.cvssV2.confidentialityImpact","impact.baseMetricV2.cvssV2.integrityImpact","impact.baseMetricV2.cvssV2.availablityImpact","impact.baseMetricV2.cvssV2.baseScore","impact.baseMetricV2.severity","impact.baseMetricV2.exploitabilityScore","impact.baseMetricV2.impactScore","impact.baseMetricV2.acInsufInfo","impact.baseMetricV2.obtainAllPrivilege","impact.baseMetricV2.obtainUserPrivilege","impact.baseMetricV2.obtainOtherPrivilege","impact.baseMetricV2.userInteractionRequired","impact.baseMetricV3.cvssV3.version","impact.baseMetricV3.cvssV3.vectorString","impact.baseMetricV3.cvssV3.attackVector","impact.baseMetricV3.cvssV3.attackComplexity","impact.baseMetricV3.cvssV3.privilegesRequired","impact.baseMetricV3.cvssV3.userInteraction","impact.baseMetricV3.cvssV3.scope","impact.baseMetricV3.cvssV3.confidentialityImpact","impact.baseMetricV3.cvssV3.integrityImpact","impact.baseMetricV3.cvssV3.availabilityImpact","impact.baseMetricV3.cvssV3.baseScore","impact.baseMetricV3.cvssV3.baseSeverity","impact.baseMetricV3.exploitabilityScore","impact.baseMetricV3.impactScore"]
    for column in impact_fields:
        if column not in df_impact.columns:
            df_impact[column] = ""

    df_concat = panda.concat([
        df_concat, 
        panda.concat([df,df_impact[impact_fields]], axis=1)
    ])
    
    file_name = "nvdcve-1.1-modified.json.gz"
    with gzip.open(base_download_path + file_name, 'r') as uf:
        json_bytes = uf.read()
    json_str = json_bytes.decode("utf-8")
    json_dict = json.loads(json_str)
    df = panda.json_normalize(json_dict, record_path="CVE_Items", meta=["CVE_data_type", "CVE_data_format"], max_level=1)
    df["object_filename"] = file_name
    df["object_download_datetime"] = datetime.date.today().strftime("%Y-%m-%d")    
    df_impact = panda.json_normalize(json_dict, record_path="CVE_Items", meta=["CVE_data_type", "CVE_data_format"], max_level=3)
    impact_fields = ["impact.baseMetricV2.cvssV2.version","impact.baseMetricV2.cvssV2.vectorString","impact.baseMetricV2.cvssV2.accessVector","impact.baseMetricV2.cvssV2.accessComplexity","impact.baseMetricV2.cvssV2.authentication","impact.baseMetricV2.cvssV2.confidentialityImpact","impact.baseMetricV2.cvssV2.integrityImpact","impact.baseMetricV2.cvssV2.availablityImpact","impact.baseMetricV2.cvssV2.baseScore","impact.baseMetricV2.severity","impact.baseMetricV2.exploitabilityScore","impact.baseMetricV2.impactScore","impact.baseMetricV2.acInsufInfo","impact.baseMetricV2.obtainAllPrivilege","impact.baseMetricV2.obtainUserPrivilege","impact.baseMetricV2.obtainOtherPrivilege","impact.baseMetricV2.userInteractionRequired","impact.baseMetricV3.cvssV3.version","impact.baseMetricV3.cvssV3.vectorString","impact.baseMetricV3.cvssV3.attackVector","impact.baseMetricV3.cvssV3.attackComplexity","impact.baseMetricV3.cvssV3.privilegesRequired","impact.baseMetricV3.cvssV3.userInteraction","impact.baseMetricV3.cvssV3.scope","impact.baseMetricV3.cvssV3.confidentialityImpact","impact.baseMetricV3.cvssV3.integrityImpact","impact.baseMetricV3.cvssV3.availabilityImpact","impact.baseMetricV3.cvssV3.baseScore","impact.baseMetricV3.cvssV3.baseSeverity","impact.baseMetricV3.exploitabilityScore","impact.baseMetricV3.impactScore"]
    for column in impact_fields:
        if column not in df_impact.columns:
            df_impact[column] = ""

    df_concat = panda.concat([
        df_concat, 
        panda.concat([df,df_impact[impact_fields]], axis=1)
    ])

    df_concat = df_concat.reset_index(drop=True)
    df_concat.index.name = "id"

    with open(base_download_path + file_name + "-tail.csv", "w") as f:
        f.write(df_concat.head(100).to_csv())

if __name__ == "__main__":
    try:
        params = {}
        input_response = ""
        use_defaults = False
        incremental = False
        if args.task_type == "download":
  #          if args.download_action:
            incremental = args.incremental
        elif args.task_type == "import":
 #           if args.import_action:
            use_defaults = args.defaults
            incremental = args.incremental
        else:
            print("Missing task type or sub-command for help use -h or --help!")
        
        method_name = args.task_type + "_feeds"
        possibles = globals().copy()
        possibles.update(locals())
        method = possibles.get(method_name)
        if not method:
            raise NotImplementedError("Method %s not implemented" % method_name)                  
        method()
    except Exception as e:
        # TODO: add logging code
        raise
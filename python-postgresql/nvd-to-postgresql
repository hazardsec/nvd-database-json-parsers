#!/usr/bin/env python3
# PYTHON_ARGCOMPLETE_OK

import argparse
from time import strftime
import requests
import pandas as pd
import numpy as np
import pyodbc
import json
import gzip
import inspect
import sys
import os
import fnmatch
import mmap
import re
import subprocess
try: 
    import argcomplete
except ImportError: 
    argcomplete = None
import shutil
import datetime

parser = argparse.ArgumentParser(description="Program for automating NVD downloads and parsing")
task_types_subparsers = parser.add_subparsers(help="Task Types or Sub-Command (type sub-command -h or --help for more info)", dest="task_type")
download_parser = task_types_subparsers.add_parser("download", help="Task for downloading NVD JSON Data Feeds")
download_options_group = download_parser.add_argument_group('Download Optional Modifiers')
#download_subparsers = download_parser.add_subparsers(help="Download Actions", dest="download_action")
download_options_group.add_argument("--incremental", dest="incremental", default=False, action="store_true", help="Only download the recent and modified NVD JSON Data Feeds")
import_parser = task_types_subparsers.add_parser("import", help="Task for importing NVD JSON Data Feeds")
import_options_group = import_parser.add_argument_group('Import Optional Modifiers')
#import_subparsers = import_parser.add_subparsers(help="Import Actions", dest="import_action")
import_options_group.add_argument("--use-defaults", dest="defaults", default=False, action="store_true", help="Use default values for import")
import_options_group.add_argument("--incremental", dest="incremental", default=False, action="store_true", help="Only import the recent and modified NVD JSON Data Feeds")

if argcomplete is not None:
    argcomplete.autocomplete(parser)

args = parser.parse_args()

def download_feeds():
    print("Hello world download!")
    years = list(range(2002, datetime.date.today().year+1))
    base_url = "https://nvd.nist.gov/feeds/json/cve/1.1/"
    base_download_path = "./downloads/"
    os.makedirs(os.path.dirname(base_download_path), exist_ok=True)
    if not incremental:
        for year in years:
            file_name = "nvdcve-1.1-" + str(year) + ".json.gz"
            file = requests.get(base_url + file_name)
            
            with open(base_download_path + file_name, "wb") as f:
                f.write(file.content)

    file_name = "nvdcve-1.1-recent.json.gz"
    file = requests.get(base_url + file_name)
    with open(base_download_path + file_name, "wb") as f:
        f.write(file.content)

    file_name = "nvdcve-1.1-modified.json.gz"
    file = requests.get(base_url + file_name)
    with open(base_download_path + file_name, "wb") as f:
        f.write(file.content)

def import_feeds():
    print("Hello world import!")
    years = list(range(2002, datetime.date.today().year+1))
    base_download_path = "./downloads/"
    cnxn_str = (
        "DRIVER={PostgreSQL ANSI};"
        "DATABASE=mgt516;"
        "UID=mgt516;"
        "PWD=<pass>;"
        "SERVER=172.27.46.71;"
        "PORT=5432;"
        )
    cnxn = pyodbc.connect(cnxn_str)
    cnxn.setencoding(encoding='utf-8')
    cnxn.setdecoding(pyodbc.SQL_CHAR, encoding='utf-8')
    cnxn.setdecoding(pyodbc.SQL_WCHAR, encoding='utf-8')
    cursor = cnxn.cursor()
    df_concat = pd.DataFrame()
    l0_fields = ["object_filename","object_download_datetime","configurations","impact","publishedDate","lastModifiedDate"]
    l1_fields = ["cve.data_type","cve.data_format","cve.data_version","cve.problemtype","cve.references","cve.description"]
    l3_fields = ["cve.CVE_data_meta.ID","cve.CVE_data_meta.ASSIGNER","impact.baseMetricV3.cvssV3.version","impact.baseMetricV3.cvssV3.vectorString","impact.baseMetricV3.cvssV3.attackVector","impact.baseMetricV3.cvssV3.attackComplexity","impact.baseMetricV3.cvssV3.privilegesRequired","impact.baseMetricV3.cvssV3.userInteraction","impact.baseMetricV3.cvssV3.scope","impact.baseMetricV3.cvssV3.confidentialityImpact","impact.baseMetricV3.cvssV3.integrityImpact","impact.baseMetricV3.cvssV3.availabilityImpact","impact.baseMetricV3.cvssV3.baseScore","impact.baseMetricV3.cvssV3.baseSeverity","impact.baseMetricV3.exploitabilityScore","impact.baseMetricV3.impactScore","impact.baseMetricV2.cvssV2.version","impact.baseMetricV2.cvssV2.vectorString","impact.baseMetricV2.cvssV2.accessVector","impact.baseMetricV2.cvssV2.accessComplexity","impact.baseMetricV2.cvssV2.authentication","impact.baseMetricV2.cvssV2.confidentialityImpact","impact.baseMetricV2.cvssV2.integrityImpact","impact.baseMetricV2.cvssV2.availabilityImpact","impact.baseMetricV2.cvssV2.baseScore","impact.baseMetricV2.severity","impact.baseMetricV2.exploitabilityScore","impact.baseMetricV2.impactScore","impact.baseMetricV2.acInsufInfo","impact.baseMetricV2.obtainAllPrivilege","impact.baseMetricV2.obtainUserPrivilege","impact.baseMetricV2.obtainOtherPrivilege","impact.baseMetricV2.userInteractionRequired"]
    if not incremental:
        for year in years:
            file_name = "nvdcve-1.1-" + str(year) + ".json.gz"
            with gzip.open(base_download_path + file_name, 'r') as uf:
                json_bytes = uf.read()
            json_str = json_bytes.decode("utf-8")
            json_dict = json.loads(json_str)

            df_l0 = pd.json_normalize(json_dict, record_path="CVE_Items", max_level=0)
            df_l0["object_filename"] = file_name
            df_l0["object_download_datetime"] = datetime.date.today().strftime("%Y-%m-%d")  

            df_l1 = pd.json_normalize(json_dict, record_path="CVE_Items", max_level=1)

            df_l3 = pd.json_normalize(json_dict, record_path="CVE_Items", max_level=3)
            for column in l3_fields:
                if column not in df_l3.columns:
                    df_l3[column] = np.nan

            df_all = pd.concat([
                df_l0[l0_fields], 
                df_l1[l1_fields],
                df_l3[l3_fields]], axis=1)

            df_concat = pd.concat([
                df_concat, 
                df_all])

    file_name = "nvdcve-1.1-recent.json.gz"
    with gzip.open(base_download_path + file_name, 'r') as uf:
        json_bytes = uf.read()
    json_str = json_bytes.decode("utf-8")
    json_dict = json.loads(json_str)
    
    df_l0 = pd.json_normalize(json_dict, record_path="CVE_Items", max_level=0)
    df_l0["object_filename"] = file_name
    df_l0["object_download_datetime"] = datetime.date.today().strftime("%Y-%m-%d")    

    df_l1 = pd.json_normalize(json_dict, record_path="CVE_Items", max_level=1)

    df_l3 = pd.json_normalize(json_dict, record_path="CVE_Items", max_level=3)
    for column in l3_fields:
        if column not in df_l3.columns:
            df_l3[column] = np.nan

    df_all = pd.concat([
        df_l0[l0_fields], 
        df_l1[l1_fields],
        df_l3[l3_fields]], axis=1)

    df_concat = pd.concat([
        df_concat, 
        df_all])

    file_name = "nvdcve-1.1-modified.json.gz"
    with gzip.open(base_download_path + file_name, 'r') as uf:
        json_bytes = uf.read()
    json_str = json_bytes.decode("utf-8")
    json_dict = json.loads(json_str)

    df_l0 = pd.json_normalize(json_dict, record_path="CVE_Items", max_level=0)
    df_l0["object_filename"] = file_name
    df_l0["object_download_datetime"] = datetime.date.today().strftime("%Y-%m-%d")    

    df_l1 = pd.json_normalize(json_dict, record_path="CVE_Items", max_level=1)

    df_l3 = pd.json_normalize(json_dict, record_path="CVE_Items", max_level=3)
    for column in l3_fields:
        if column not in df_l3.columns:
            df_l3[column] = np.nan

    df_all = pd.concat([
        df_l0[l0_fields], 
        df_l1[l1_fields],
        df_l3[l3_fields]], axis=1)

    df_concat = pd.concat([
        df_concat, 
        df_all])

    #with open(base_download_path + file_name + "-test.json", "w") as f:
    #    f.write(df_concat.tail(1428).to_json(orient="records"))

    df_concat = df_concat.reset_index(drop=True)
    df_concat.index.name = "id"

    cursor.execute("""INSERT INTO public.nvd_import 
        SELECT j->>'object_filename' AS object_filename
        ,TO_TIMESTAMP(j->>'object_download_datetime', 'YYYY-MM-DD') AS object_download_datetime
        ,j->>'cve.data_type' AS item_cve_data_type
        ,j->>'cve.data_format' AS item_cve_data_format
        ,CAST(j->>'cve.data_version' AS DECIMAL) AS item_cve_data_version 
        ,j->>'cve.CVE_data_meta.ID' AS item_cve_data_meta_id
        ,j->>'cve.CVE_data_meta.ASSIGNER' AS item_cve_data_meta_assigner
        ,j->'cve.problemtype' AS item_cve_problemtype
        ,j->'cve.references' AS item_cve_references
        ,j->'cve.description'->'description_data'->0->>'value' AS item_cve_primary_description
        ,j->'cve.description' AS item_cve_description
        ,j->'configurations' AS item_configuraitons
        ,j->'impact' AS item_impact        
        ,TO_TIMESTAMP(j->>'publishedDate', 'YYYY-MM-DDTHH24:MIZ') AS item_published_datetime 
        ,TO_TIMESTAMP(j->>'lastModifiedDate', 'YYYY-MM-DDTHH24:MIZ') AS item_modified_datetime
        ,CAST(j->>'impact.baseMetricV3.exploitabilityScore' AS DECIMAL) AS impact_v3_exploitability_score
        ,CAST(j->>'impact.baseMetricV3.impactScore' AS DECIMAL) AS impact_v3_impact_score
        ,CAST(j->>'impact.baseMetricV3.cvssV3.version' AS DECIMAL) AS item_v3_version
        ,j->>'impact.baseMetricV3.cvssV3.vectorString' AS impact_v3_vector_sting
        ,j->>'impact.baseMetricV3.cvssV3.attackVector' AS impact_v3_attack_vector
        ,j->>'impact.baseMetricV3.cvssV3.attackComplexity' AS impact_v3_attack_complexity
        ,j->>'impact.baseMetricV3.cvssV3.privilegesRequired' AS impact_v3_privileges_required
        ,j->>'impact.baseMetricV3.cvssV3.userInteraction' AS impact_v3_user_interaction
        ,j->>'impact.baseMetricV3.cvssV3.scope' AS impact_v3_scope
        ,j->>'impact.baseMetricV3.cvssV3.confidentialityImpact' AS impact_v3_confidentiality_impact 
        ,j->>'impact.baseMetricV3.cvssV3.integrityImpact' AS impact_v3_integrity_impact
        ,j->>'impact.baseMetricV3.cvssV3.availabilityImpact' AS impact_v3_availability_impact
        ,CAST(j->>'impact.baseMetricV3.cvssV3.baseScore' AS DECIMAL) AS impact_v3_base_score
        ,j->>'impact.baseMetricV3.cvssV3.baseSeverity' AS impact_v3_base_severity
        ,j->>'impact.baseMetricV2.severity' AS impact_v2_severity
        ,CAST(NULLIF(j->>'impact.baseMetricV2.exploitabilityScore', '0.0') AS DECIMAL) AS impact_v2_exploitability_score
        ,CAST(NULLIF(j->>'impact.baseMetricV2.impactScore', '0.0') AS DECIMAL) AS impact_v2_impact_score
        ,j->>'impact.baseMetricV2.acInsufInfo' AS impact_v2_acinsufinfo
        ,j->>'impact.baseMetricV2.obtainAllPrivilege' AS impact_v2_obtain_all_privilege
        ,j->>'impact.baseMetricV2.obtainUserPrivilege' AS impact_v2_obtain_user_privilege
        ,j->>'impact.baseMetricV2.obtainOtherPrivilege' AS impact_v2_obtain_other_privilege
        ,j->>'impact.baseMetricV2.userInteractionRequired' AS impact_v2_user_interaction_required
        ,CAST(NULLIF(j->>'impact.baseMetricV2.cvssV2.version', '0.0') AS DECIMAL) AS impact_v2_version
        ,j->>'impact.baseMetricV2.cvssV2.vectorString' AS impact_v2_vector_string
        ,j->>'impact.baseMetricV2.cvssV2.accessVector' AS impact_v2_access_vector
        ,j->>'impact.baseMetricV2.cvssV2.accessComplexity' AS impact_v2_access_complexity
        ,j->>'impact.baseMetricV2.cvssV2.authentication' AS impact_v2_authentication
        ,j->>'impact.baseMetricV2.cvssV2.confidentialityImpact' AS impact_v2_confidentiality_impact
        ,j->>'impact.baseMetricV2.cvssV2.integrityImpact' AS impact_v2_integrity_impact
        ,j->>'impact.baseMetricV2.cvssV2.availabilityImpact' AS impact_v2_availability_impact
        ,CAST(NULLIF(j->>'impact.baseMetricV2.cvssV2.baseScore', '0.0') AS DECIMAL) AS impact_v2_base_score        
        From JSON_ARRAY_ELEMENTS(?) AS j """, df_concat.to_json(orient="records"))

    cnxn.commit()
    cnxn.close()

if __name__ == "__main__":
    try:
        params = {}
        input_response = ""
        use_defaults = False
        incremental = False
        if args.task_type == "download":
  #          if args.download_action:
            incremental = args.incremental
        elif args.task_type == "import":
 #           if args.import_action:
            use_defaults = args.defaults
            incremental = args.incremental
        else:
            print("Missing task type or sub-command for help use -h or --help!")
        
        method_name = args.task_type + "_feeds"
        possibles = globals().copy()
        possibles.update(locals())
        method = possibles.get(method_name)
        if not method:
            raise NotImplementedError("Method %s not implemented" % method_name)                  
        method()
    except Exception as e:
        # TODO: add logging code
        raise